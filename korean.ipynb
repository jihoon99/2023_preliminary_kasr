{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"kresnik/wav2vec2-large-xlsr-korean\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"kresnik/wav2vec2-large-xlsr-korean\").to('cuda')\n",
    "ds = load_dataset(\"kresnik/zeroth_korean\", 'clean')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "from transformers import AutoProcessor\n",
    "from transformers import (AutoProcessor, Wav2Vec2Processor, Wav2Vec2ForCTC, Wav2Vec2CTCTokenizer)\n",
    "import soundfile as sf\n",
    "from jiwer import wer\n",
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "\n",
    "# ds = load_dataset(\"kresnik/zeroth_korean\", 'clean')\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"kresnik/wav2vec2-large-xlsr-korean\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"kresnik/wav2vec2-large-xlsr-korean\").to('cuda')\n",
    "# tokenizer = Wav2Vec2CTCTokenizer(\"kresnik/wav2vec2-large-xlsr-korean\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ = '/content/sample_001.wav'\n",
    "search_, _ = sf.read(file_)\n",
    "inputs = processor(speech_, sampling_rate=16_000, return_tensors='pt', padding='longest')\n",
    "input_values = inputs['input_values'].to(\"cuda\")\n",
    "logits = model(input_values).logits  # bs, seq, vocab\n",
    "predicted_ids = torch.argmax(logits, dim = -1)\n",
    "transcription = preocessor.batch_decode(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'kresnik/wav2vec2-large-xlsr-korean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[39m=\u001b[39m Wav2Vec2CTCTokenizer(\u001b[39m\"\u001b[39;49m\u001b[39mkresnik/wav2vec2-large-xlsr-korean\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/w2v/lib/python3.9/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:187\u001b[0m, in \u001b[0;36mWav2Vec2CTCTokenizer.__init__\u001b[0;34m(self, vocab_file, bos_token, eos_token, unk_token, pad_token, word_delimiter_token, replace_word_delimiter_char, do_lower_case, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_lower_case \u001b[39m=\u001b[39m do_lower_case\n\u001b[1;32m    185\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplace_word_delimiter_char \u001b[39m=\u001b[39m replace_word_delimiter_char\n\u001b[0;32m--> 187\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(vocab_file, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m vocab_handle:\n\u001b[1;32m    188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(vocab_handle)\n\u001b[1;32m    189\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m {v: k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mitems()}\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'kresnik/wav2vec2-large-xlsr-korean'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jiwer in /home/rainism/anaconda3/envs/w2v/lib/python3.9/site-packages (3.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /home/rainism/anaconda3/envs/w2v/lib/python3.9/site-packages (from jiwer) (8.1.7)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in /home/rainism/anaconda3/envs/w2v/lib/python3.9/site-packages (from jiwer) (3.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset timit_asr (/home/rainism/.cache/huggingface/datasets/timit_asr/clean/2.0.1/b11b576ddcccbcefa7c9f0c4e6c2a43756f3033adffe0fb686aa61043d0450ad)\n",
      "100%|██████████| 2/2 [00:00<00:00, 34.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "import pandas as pd\n",
    "\n",
    "timit = load_dataset(\"timit_asr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>audio</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/rainism/.cache/huggingface/datasets/down...</td>\n",
       "      <td>{'path': '/home/rainism/.cache/huggingface/dat...</td>\n",
       "      <td>Would such an act of refusal be useful?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/rainism/.cache/huggingface/datasets/down...</td>\n",
       "      <td>{'path': '/home/rainism/.cache/huggingface/dat...</td>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/rainism/.cache/huggingface/datasets/down...</td>\n",
       "      <td>{'path': '/home/rainism/.cache/huggingface/dat...</td>\n",
       "      <td>Butterscotch fudge goes well with vanilla ice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/rainism/.cache/huggingface/datasets/down...</td>\n",
       "      <td>{'path': '/home/rainism/.cache/huggingface/dat...</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/rainism/.cache/huggingface/datasets/down...</td>\n",
       "      <td>{'path': '/home/rainism/.cache/huggingface/dat...</td>\n",
       "      <td>I honor my mom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>/home/rainism/.cache/huggingface/datasets/down...</td>\n",
       "      <td>{'path': '/home/rainism/.cache/huggingface/dat...</td>\n",
       "      <td>She had your dark suit in greasy wash water al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4616</th>\n",
       "      <td>/home/rainism/.cache/huggingface/datasets/down...</td>\n",
       "      <td>{'path': '/home/rainism/.cache/huggingface/dat...</td>\n",
       "      <td>The water contained too much chlorine and stun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>/home/rainism/.cache/huggingface/datasets/down...</td>\n",
       "      <td>{'path': '/home/rainism/.cache/huggingface/dat...</td>\n",
       "      <td>Movies never have enough villains.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>/home/rainism/.cache/huggingface/datasets/down...</td>\n",
       "      <td>{'path': '/home/rainism/.cache/huggingface/dat...</td>\n",
       "      <td>Does Hindu ideology honor cows?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>/home/rainism/.cache/huggingface/datasets/down...</td>\n",
       "      <td>{'path': '/home/rainism/.cache/huggingface/dat...</td>\n",
       "      <td>Gus saw pine trees and redwoods on his walk th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4620 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   file  \\\n",
       "0     /home/rainism/.cache/huggingface/datasets/down...   \n",
       "1     /home/rainism/.cache/huggingface/datasets/down...   \n",
       "2     /home/rainism/.cache/huggingface/datasets/down...   \n",
       "3     /home/rainism/.cache/huggingface/datasets/down...   \n",
       "4     /home/rainism/.cache/huggingface/datasets/down...   \n",
       "...                                                 ...   \n",
       "4615  /home/rainism/.cache/huggingface/datasets/down...   \n",
       "4616  /home/rainism/.cache/huggingface/datasets/down...   \n",
       "4617  /home/rainism/.cache/huggingface/datasets/down...   \n",
       "4618  /home/rainism/.cache/huggingface/datasets/down...   \n",
       "4619  /home/rainism/.cache/huggingface/datasets/down...   \n",
       "\n",
       "                                                  audio  \\\n",
       "0     {'path': '/home/rainism/.cache/huggingface/dat...   \n",
       "1     {'path': '/home/rainism/.cache/huggingface/dat...   \n",
       "2     {'path': '/home/rainism/.cache/huggingface/dat...   \n",
       "3     {'path': '/home/rainism/.cache/huggingface/dat...   \n",
       "4     {'path': '/home/rainism/.cache/huggingface/dat...   \n",
       "...                                                 ...   \n",
       "4615  {'path': '/home/rainism/.cache/huggingface/dat...   \n",
       "4616  {'path': '/home/rainism/.cache/huggingface/dat...   \n",
       "4617  {'path': '/home/rainism/.cache/huggingface/dat...   \n",
       "4618  {'path': '/home/rainism/.cache/huggingface/dat...   \n",
       "4619  {'path': '/home/rainism/.cache/huggingface/dat...   \n",
       "\n",
       "                                                   text  \n",
       "0               Would such an act of refusal be useful?  \n",
       "1          Don't ask me to carry an oily rag like that.  \n",
       "2     Butterscotch fudge goes well with vanilla ice ...  \n",
       "3     She had your dark suit in greasy wash water al...  \n",
       "4                                       I honor my mom.  \n",
       "...                                                 ...  \n",
       "4615  She had your dark suit in greasy wash water al...  \n",
       "4616  The water contained too much chlorine and stun...  \n",
       "4617                 Movies never have enough villains.  \n",
       "4618                    Does Hindu ideology honor cows?  \n",
       "4619  Gus saw pine trees and redwoods on his walk th...  \n",
       "\n",
       "[4620 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit = timit.remove_columns([\"phonetic_detail\", \"word_detail\", \"dialect_region\", \"id\", \"sentence_type\", \"speaker_id\"])\n",
    "pd.DataFrame(timit['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39936,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(timit['train'])['audio'].iloc[0]['array'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n",
    "\n",
    "\n",
    "processor.batch_decode\n",
    "\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower() + \" \"\n",
    "    return batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
